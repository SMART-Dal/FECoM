"""
Tools for analysing the data generated by the Experiments.
"""
import os
import json
from pathlib import Path

import pandas as pd

from tool.experiment.experiments import format_full_output_dir, ExperimentKinds
from tool.server.server_config import STABLE_CPU_ENERGY_MEAN, STABLE_RAM_ENERGY_MEAN, STABLE_GPU_POWER_MEAN

# one data sample, as obtained from one server response
class EnergyData():
    def __init__(self, function_name, cpu_energy: pd.DataFrame, ram_energy: pd.DataFrame, gpu_energy: pd.DataFrame, times, input_sizes):
        self.function_name = function_name
        self.cpu_energy = cpu_energy
        self.ram_energy = ram_energy
        self.gpu_energy = gpu_energy
        self.times = times
        self.input_sizes = input_sizes

        self.cpu_energy_in_execution = self.__energy_in_execution(cpu_energy, times["start_time_perf"], times["end_time_perf"])
        self.ram_energy_in_execution = self.__energy_in_execution(ram_energy, times["start_time_perf"], times["end_time_perf"])
        self.gpu_energy_in_execution = self.__energy_in_execution(gpu_energy, times["start_time_nvidia"], times["end_time_nvidia"])
    
    def __str__(self):
        return f"EnergyData of {self.function_name}\nCPU ENERGY:\n{str(self.cpu_energy)}\nRAM ENERGY:\n{self.ram_energy}\nGPU ENERGY:\n{self.gpu_energy}\n TIMES:\n{self.times}\n INPUT SIZES:\n{self.input_sizes}"
    
    @property
    def total_cpu(self):
        # make sure that the filtering works: first time stamp must be start_time_perf and last time stamp must be end_time_perf,
        # since the server reads these times from the perf files
        assert self.cpu_energy_in_execution["time_elapsed"].iloc[0] == self.times["start_time_perf"]
        assert self.cpu_energy_in_execution["time_elapsed"].iloc[-1] == self.times["end_time_perf"]
        # return the total energy consumption
        return self.cpu_energy_in_execution["energy (J)"].sum()
    
    @property
    def total_cpu_normalised(self):
        return self.__total_normalised(self.cpu_energy_in_execution, STABLE_CPU_ENERGY_MEAN, self.total_cpu)
    
    @property
    def total_ram(self):
        # make sure that the filtering works: first time stamp must be start_time_perf and last time stamp must be end_time_perf,
        # since the server reads these times from the perf files
        assert self.ram_energy_in_execution["time_elapsed"].iloc[0] == self.times["start_time_perf"]
        assert self.ram_energy_in_execution["time_elapsed"].iloc[-1] == self.times["end_time_perf"]
        # return the total energy consumption
        return self.ram_energy_in_execution["energy (J)"].sum()
    
    @property
    def total_ram_normalised(self):
        return self.__total_normalised(self.ram_energy_in_execution, STABLE_RAM_ENERGY_MEAN, self.total_ram)
    
    @property
    def total_gpu(self):
        # for the gpu data we have slightly weaker assumptions than for the cpu data, since we "normalise"
        # the gpu time_elapsed & start/end times and limited floating point precision can lead to slight differences in the values
        assert self.gpu_energy_in_execution["time_elapsed"].iloc[0] >= self.times["start_time_nvidia"]
        assert self.gpu_energy_in_execution["time_elapsed"].iloc[-1] <= self.times["end_time_nvidia"]
        return self.gpu_energy_in_execution["power_draw (W)"].sum()

    @property
    def total_gpu_normalised(self):
        return self.__total_normalised(self.gpu_energy_in_execution, STABLE_GPU_POWER_MEAN, self.total_gpu)
    
    @property
    # how long did the server check for stable state?
    def stable_check_waiting_time_s(self):
        return (self.times["start_time_server"]-self.times["begin_stable_check_time"])/1_000_000_000
    
    def __energy_in_execution(self, energy_df: pd.DataFrame, start_time: float, end_time: float):
        # get the energy data in between execution start and end time
        energy_in_execution = energy_df.loc[(energy_df["time_elapsed"]>= start_time) & (energy_df["time_elapsed"]<= end_time)]
        return energy_in_execution

    def __total_normalised(self, energy_in_execution_df: pd.DataFrame, stable_energy_mean: float, total_energy: float):
        n_data_points = len(energy_in_execution_df)
        baseline_energy_consumption = stable_energy_mean * n_data_points
        return total_energy - baseline_energy_consumption


class DataLoader():
    def __init__(self, project: str, output_dir: Path, experiment_kind: ExperimentKinds):
        self.experiment_kind = experiment_kind
        self.__data_dir = format_full_output_dir(output_dir, experiment_kind.value, project)
    
    def get_all_data_files(self) -> list:
        return os.listdir(self.__data_dir)

    # returns a list of EnergyData objects where self.function_name is
    # - the function name (method-level experiment)
    # - "project-level" (project-level experiment), in this case there is only one dict in the list
    def load_single_file(self, file_name: str) -> list:
        file_path = self.__data_dir / file_name
        with open(file_path, 'r') as f:
            raw_data_list = json.load(f)
        
        data_samples = []

        # iterate through all samples in the file and create EnergyData objects for them
        for data_dict in raw_data_list:
            # data_dict has only one key, the function name
            function_name = list(data_dict.keys())[0]
            energy_data = data_dict[function_name]["energy_data"]
            data_samples.append(EnergyData(
                function_name,
                self.convert_json_dict_to_df(energy_data["cpu"]),
                self.convert_json_dict_to_df(energy_data["ram"]),
                self.convert_json_dict_to_df(energy_data["gpu"]),
                data_dict[function_name]["times"],
                data_dict[function_name]["input_sizes"]
            ))

        return data_samples
        
    def convert_json_dict_to_df(self, energy_data: dict) -> pd.DataFrame:
        return pd.read_json(energy_data, orient="split")



if __name__ == "__main__":
    from tool.client.client_config import EXPERIMENT_DIR
    dl = DataLoader("keras/classification", EXPERIMENT_DIR, ExperimentKinds.PROJECT_LEVEL)
    data_files = dl.get_all_data_files()
    print(data_files)
    example_data = dl.load_single_file(data_files[1])[1]
    print("CPU")
    print(example_data.total_cpu)
    print(example_data.total_cpu_normalised)
    print("RAM")
    print(example_data.total_ram)
    print(example_data.total_ram_normalised)
    print("GPU")
    print(example_data.total_gpu)
    print(example_data.total_gpu_normalised)